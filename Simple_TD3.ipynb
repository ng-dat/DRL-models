{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple TD3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOydq/vsYx1F9qcW3TY79zU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nguyencongdat1997/RL.TryOut/blob/developments-ppo/Simple_TD3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXq4ga96ssF3"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsWq1yvNJN51"
      },
      "source": [
        "!pip3 install box2d-py\n",
        "!pip3 install gym[Box_2D]\n",
        "# import gym\n",
        "# env = gym.make(\"LunarLander-v2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWnUGUsysLA9"
      },
      "source": [
        "import gym\n",
        "import random"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYrcJIslHH1A",
        "outputId": "e01752de-d68d-4d3d-f5e8-1e3017650e02"
      },
      "source": [
        "env = gym.make('BipedalWalker-v3')\n",
        "observation_space = env.observation_space.shape\n",
        "action_space = env.action_space"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om8yPoDZHLeS",
        "outputId": "3f137998-5b8e-467c-95e0-894d15c6d1a6"
      },
      "source": [
        "print(action_space)\n",
        "sample_action = env.action_space.sample()\n",
        "print(sample_action)\n",
        "print(observation_space)\n",
        "state = env.reset()\n",
        "print(state)\n",
        "state, reward, done, info = env.step(sample_action)\n",
        "print(state, reward, done, info)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Box(-1.0, 1.0, (4,), float32)\n",
            "[ 0.469193    0.25351194 -0.31617004 -0.04958845]\n",
            "(24,)\n",
            "[ 2.74728681e-03 -2.54253182e-05  1.97782919e-03 -1.59998310e-02\n",
            "  9.18016657e-02 -2.61006295e-03  8.60359177e-01  3.33123623e-03\n",
            "  1.00000000e+00  3.22064571e-02 -2.60988181e-03  8.53910506e-01\n",
            "  1.84586008e-03  1.00000000e+00  4.40814108e-01  4.45820212e-01\n",
            "  4.61422890e-01  4.89550292e-01  5.34102917e-01  6.02461159e-01\n",
            "  7.09149063e-01  8.85932028e-01  1.00000000e+00  1.00000000e+00]\n",
            "[-7.42478482e-03 -4.42126274e-03  5.50986570e-05  1.97055966e-03\n",
            "  4.31892902e-01  1.68765299e-02  1.26283109e-01  1.78932200e-02\n",
            "  1.00000000e+00  3.34521085e-01 -4.09391820e-02  1.27468228e-01\n",
            "  9.51383909e-02  1.00000000e+00  4.50682491e-01  4.55800682e-01\n",
            "  4.71752614e-01  5.00509739e-01  5.46059728e-01  6.15948260e-01\n",
            "  7.25024581e-01  9.05765116e-01  1.00000000e+00  1.00000000e+00] -0.11933500264522812 False {}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3JUBB2DPoZu",
        "outputId": "0f23e0cd-72aa-4151-e398-56b946386883"
      },
      "source": [
        "episodes = 3\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0 \n",
        "    steps = 0\n",
        "    while not done:\n",
        "        # env.render()\n",
        "        mu = np.random.normal(scale=1, size=(env.action_space.shape[0]))\n",
        "        clipped_mu = tf.clip_by_value(mu, env.action_space.low[0], env.action_space.high[0])\n",
        "        action = clipped_mu\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score += reward\n",
        "        steps += 1\n",
        "    print('Episode:{} Steps:{} Score:{}'.format(episode, steps, score))\n",
        "env.close()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode:1 Steps:1600 Score:-115.95905863500562\n",
            "Episode:2 Steps:1600 Score:-106.30904355188133\n",
            "Episode:3 Steps:1544 Score:-220.36528954173832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuCo8r734nQb"
      },
      "source": [
        "# TD3 tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNaQ7TEY4nQd"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "w8hVyanBxbsB",
        "outputId": "456e7ec1-9a36-4318-e112-0ecbb58444ba"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__ #2.5.0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAUpAPJTvk4r"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Convolution2D\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmrkGO-s4nQe"
      },
      "source": [
        "## Experience Replay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4iv7cxvvvoV"
      },
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self, max_size, input_shape, n_actions):\n",
        "        self.mem_size = max_size\n",
        "        self.mem_counter = 0\n",
        "\n",
        "        self.states = np.zeros((self.mem_size, *input_shape), dtype=np.float32)\n",
        "        self.next_states = np.zeros((self.mem_size, *input_shape), dtype=np.float32)\n",
        "        self.rewards = np.zeros(self.mem_size, dtype=np.float32)\n",
        "        self.actions = np.zeros((self.mem_size, n_actions), dtype=np.float32)\n",
        "        self.done = np.zeros(self.mem_size, dtype=np.bool)\n",
        "\n",
        "    def store_step(self, state, action, reward, next_state, done):\n",
        "        index = self.mem_counter % self.mem_size\n",
        "        self.states[index] = state\n",
        "        self.next_states[index] = next_state\n",
        "        self.actions[index] = action\n",
        "        self.rewards[index] = reward\n",
        "        self.done[index] = done\n",
        "        self.mem_counter += 1\n",
        "\n",
        "    def sample_buffer(self, batch_size):\n",
        "        # if batch_size > self.mem_counter:\n",
        "        #   return [], [], [], [], []\n",
        "        max_mem = min(self.mem_counter, self.mem_size)\n",
        "        batch = np.random.choice(max_mem, batch_size, replace=False)\n",
        "\n",
        "        states = self.states[batch]\n",
        "        next_states = self.next_states[batch]\n",
        "        rewards = self.rewards[batch]\n",
        "        actions = self.actions[batch]\n",
        "        dones = self.done[batch]\n",
        "\n",
        "        return states, actions, rewards, next_states, dones\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOwvvQiI4nQg"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlcesD9JwtU1"
      },
      "source": [
        "class Critic(keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Critic, self).__init__()\n",
        "        l1_dims = 400 # As tested in the paper\n",
        "        l2_dims = 300 # As tested in the paper\n",
        "\n",
        "        self.fc1 = Dense(l1_dims, activation='relu') #input_shape  = state, action\n",
        "        self.fc2 = Dense(l2_dims, activation='relu')\n",
        "        self.q = Dense(1, activation=None)\n",
        "\n",
        "    def call(self, state, action):\n",
        "        input = tf.concat([state, action], axis=1)\n",
        "        x = self.fc1(input)\n",
        "        x = self.fc2(x)\n",
        "        q = self.q(x)\n",
        "        return q"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utvG10nPyqeZ"
      },
      "source": [
        "class Actor(keras.Model):\n",
        "    def __init__(self, n_actions):\n",
        "        super(Actor, self).__init__()\n",
        "        l1_dims = 400 # As tested in the paper\n",
        "        l2_dims = 300 # As tested in the paper\n",
        "        self.n_actions = n_actions\n",
        "\n",
        "        self.fc1 = Dense(l1_dims, activation='relu') #input_shape  = state\n",
        "        self.fc2 = Dense(l2_dims, activation='relu')\n",
        "        self.mu = Dense(self.n_actions, activation='tanh')\n",
        "\n",
        "    def call(self, state):        \n",
        "        x = self.fc1(state)\n",
        "        x = self.fc2(x)\n",
        "        mu = self.mu(x)\n",
        "        return mu"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWe_oqBC4nQh"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp1pRh-zz86Z"
      },
      "source": [
        "class Agent():\n",
        "    def __init__(self, observation_shape, n_actions, max_action, min_action, \n",
        "                 actor_learning_rate=0.001, critic_learning_rate=0.001, tau=0.005, gamma=0.99, \n",
        "                 delayed_policy_update_interval=2, exploration_noise_std=0.1, \n",
        "                 smoothing_noise_std=0.2, smoothing_noise_limit=0.5,\n",
        "                 mem_size=1000000, batch_size=100):\n",
        "        self.n_actions = n_actions\n",
        "        self.max_action = max_action\n",
        "        self.min_action = min_action\n",
        "        self.gamma = gamma        \n",
        "        self.tau = tau        \n",
        "        self.delayed_policy_update_interval = delayed_policy_update_interval\n",
        "        self.exploration_noise_std = exploration_noise_std\n",
        "        self.smoothing_noise_std = smoothing_noise_std\n",
        "        self.smoothing_noise_limit = smoothing_noise_limit\n",
        "        self.batch_size = batch_size               \n",
        "\n",
        "        self.learned_step_counter = 0        \n",
        "        self.memory = ReplayBuffer(mem_size, observation_shape, n_actions)\n",
        "        self.actor = Actor(n_actions)\n",
        "        self.critic1 = Critic()\n",
        "        self.critic2 = Critic()\n",
        "        self.target_actor = Actor(n_actions)\n",
        "        self.target_critic1 = Critic()\n",
        "        self.target_critic2 = Critic()\n",
        "\n",
        "        self.actor.compile(optimizer=Adam(learning_rate=actor_learning_rate), loss='mean')\n",
        "        self.target_actor.compile(optimizer=Adam(learning_rate=actor_learning_rate), loss='mean')\n",
        "        self.critic1.compile(optimizer=Adam(learning_rate=critic_learning_rate), loss='mean_squared_error')\n",
        "        self.critic2.compile(optimizer=Adam(learning_rate=critic_learning_rate), loss='mean_squared_error')\n",
        "        self.target_critic1.compile(optimizer=Adam(learning_rate=critic_learning_rate), loss='mean_squared_error')\n",
        "        self.target_critic2.compile(optimizer=Adam(learning_rate=critic_learning_rate), loss='mean_squared_error')\n",
        "        \n",
        "        self.soft_update_target_network_parameters(tau=1)    \n",
        "    \n",
        "    def choose_action(self, observation, explorating=False):\n",
        "        # if self.time_step < self.warmup:\n",
        "        #     mu = np.random.normal(scale=self.exploration_noise_std, size=(self.n_actions)) #size=(self.n_actions,)\n",
        "        # else:\n",
        "            state = np.array([observation])\n",
        "            state = tf.convert_to_tensor(state, dtype=tf.float32)\n",
        "            mu = self.actor(state)[0]\n",
        "            if explorating:                \n",
        "                mu = mu + np.random.normal(scale=self.exploration_noise_std)\n",
        "            clipped_mu = tf.clip_by_value(mu, self.min_action, self.max_action)\n",
        "            return clipped_mu\n",
        "    \n",
        "    def store_step(self, state, action, reward, next_state, done):\n",
        "        self.memory.store_step(state, action, reward, next_state, done)\n",
        "       \n",
        "    def run_warmup(self, env, warmup):\n",
        "        print('Run warmup ----------')       \n",
        "        steps = 0        \n",
        "        while steps < warmup:\n",
        "            done = False\n",
        "            observation = env.reset()\n",
        "            while not done:\n",
        "                steps += 1\n",
        "                mu = np.random.normal(scale=self.exploration_noise_std, size=(self.n_actions))\n",
        "                clipped_mu = tf.clip_by_value(mu, self.min_action, self.max_action)\n",
        "                action = clipped_mu\n",
        "                next_observation, reward, done, info = env.step(action)\n",
        "                self.store_step(observation, action, reward, next_observation, done)\n",
        "                observation = next_observation                  \n",
        "\n",
        "    def train(self, env, n_games, warmup=1000):\n",
        "        if warmup > 0:\n",
        "            self.run_warmup(env, warmup)\n",
        "\n",
        "        print('Start training ----------')  \n",
        "        best_score = env.reward_range[0]\n",
        "        scores = []\n",
        "        time_steps = 0\n",
        "        for i in range(n_games):\n",
        "            done = False\n",
        "            score = 0\n",
        "            observation = env.reset()\n",
        "            while not done:\n",
        "                time_steps += 1\n",
        "                action = self.choose_action(observation, explorating=True)\n",
        "                next_observation, reward, done, info = env.step(action)\n",
        "                score += reward\n",
        "                self.store_step(observation, action, reward, next_observation, done)\n",
        "                self.learn()\n",
        "                observation = next_observation\n",
        "                self.learn()\n",
        "\n",
        "            scores.append(score)\n",
        "            avg_score = np.mean(scores[-10:])\n",
        "            if avg_score > best_score:\n",
        "                best_score = avg_score\n",
        "                if best_score > 250:\n",
        "                    self.save_models(train_dir='.')\n",
        "            print('Episode', i, '- trained steps', time_steps, '- score %.1f'%score, '- avg_score %.1f ' % avg_score)\n",
        "        print('End training ----------')  \n",
        "\n",
        "    def learn(self):\n",
        "        if self.memory.mem_counter < self.batch_size:\n",
        "            return\n",
        "\n",
        "        states, actions, rewards, next_states, dones = self.memory.sample_buffer(self.batch_size)\n",
        "        states = tf.convert_to_tensor(states, dtype=tf.float32)\n",
        "        actions = tf.convert_to_tensor(actions, dtype=tf.float32)\n",
        "        rewards = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
        "        next_states = tf.convert_to_tensor(next_states, dtype=tf.float32)\n",
        "\n",
        "        with tf.GradientTape(persistent=True) as tape: # <- 2 networks update\n",
        "            target_actions = self.target_actor(next_states)\n",
        "            smoothing_noise = tf.clip_by_value(np.random.normal(scale=self.smoothing_noise_std), \n",
        "                                    -1*self.smoothing_noise_limit, self.smoothing_noise_limit)            \n",
        "            target_actions = target_actions + smoothing_noise\n",
        "            target_actions = tf.clip_by_value(target_actions, self.min_action, self.max_action)\n",
        "\n",
        "            next_q1 = self.target_critic1(next_states, target_actions)\n",
        "            next_q1 = tf.squeeze(next_q1, 1) # [batch_size, 1] -> [batch_size]\n",
        "            next_q2 = self.target_critic2(next_states, target_actions)\n",
        "            next_q2 = tf.squeeze(next_q2, 1)\n",
        "            next_q = tf.math.minimum(next_q1, next_q2)\n",
        "\n",
        "            q1 = self.critic1(states, actions)\n",
        "            q1 = tf.squeeze(q1, 1) \n",
        "            q2 = self.critic2(states, actions)\n",
        "            q2 = tf.squeeze(q2, 1) \n",
        "            \n",
        "            target = rewards + self.gamma*next_q*(1-dones)\n",
        "\n",
        "            critic1_loss = keras.losses.MSE(target, q1)\n",
        "            critic2_loss = keras.losses.MSE(target, q2)\n",
        "        critic1_gradient = tape.gradient(critic1_loss, self.critic1.trainable_variables)\n",
        "        critic2_gradient = tape.gradient(critic2_loss, self.critic2.trainable_variables)\n",
        "        self.critic1.optimizer.apply_gradients(zip(critic1_gradient, self.critic1.trainable_variables))\n",
        "        self.critic2.optimizer.apply_gradients(zip(critic2_gradient, self.critic2.trainable_variables))\n",
        "\n",
        "        self.learned_step_counter += 1\n",
        "\n",
        "        if self.learned_step_counter+1 % self.delayed_policy_update_interval == 0:\n",
        "            with tf.GradientTape() as tape:\n",
        "                new_actions = self.actor(states)\n",
        "                q = self.critic1(states, new_actions)\n",
        "                actor_loss =  -1 * tf.math.reduce_mean(q)\n",
        "            actor_gradient = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
        "            self.actor.optimizer.apply_gradients(zip(actor_gradient, self.actor.trainable_variables))\n",
        "\n",
        "            self.soft_update_target_network_parameters(tau=self.tau)\n",
        "\n",
        "    def soft_update_target_network_parameters(self, tau):\n",
        "        weights = []\n",
        "        targets = self.target_actor.weights\n",
        "        for i, weight in enumerate(self.actor.weights):\n",
        "            weights.append(weight*tau + targets[i]*(1-tau))\n",
        "        self.target_actor.set_weights(weights)\n",
        "\n",
        "        weights = []\n",
        "        targets = self.target_critic1.weights\n",
        "        for i, weight in enumerate(self.critic1.weights):\n",
        "            weights.append(weight*tau + targets[i]*(1-tau))\n",
        "        self.target_critic1.set_weights(weights)\n",
        "\n",
        "        weights = []\n",
        "        targets = self.target_critic2.weights\n",
        "        for i, weight in enumerate(self.critic2.weights):\n",
        "            weights.append(weight*tau + targets[i]*(1-tau))\n",
        "        self.target_critic2.set_weights(weights)\n",
        "\n",
        "    def save_models(self, train_dir):\n",
        "        pass\n",
        "        # train_dir = train_dir + '/td3_' + str(self.learned_step_counter) \n",
        "        # self.actor.save_weights(train-dir+'/actor/model')\n",
        "        # self.critic1.save_weights(train-dir+'/critic1/model')\n",
        "        # self.critic2.save_weights(train-dir+'/critic2/model')\n",
        "        # self.target_actor.save_weights(train-dir+'/target_actor/model')\n",
        "        # self.target_critic1.save_weights(train-dir+'/target_critic1/model')\n",
        "        # self.target_critic2.save_weights(train-dir+'/target_critic2/model')\n",
        "\n",
        "    def load_models(self, train_dir, learned_steps = 100):\n",
        "        pass\n",
        "        # train_dir = train_dir + '/td3_' + str(learned_steps) \n",
        "        # self.actor.load_weights(train-dir+'/actor/model')\n",
        "        # self.critic1.load_weights(train-dir+'/critic1/model')\n",
        "        # self.critic2.load_weights(train-dir+'/critic2/model')\n",
        "        # self.target_actor.load_weights(train-dir+'/target_actor/model')\n",
        "        # self.target_critic1.load_weights(train-dir+'/target_critic1/model')\n",
        "        # self.target_critic2.load_weights(train-dir+'/target_critic2/model')\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t66JBkJA4nQi"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ssk7wsKHGRV7",
        "outputId": "c56cd8e2-fbad-48cf-ee90-800f7b0e10df"
      },
      "source": [
        "agent = Agent(observation_shape=env.observation_space.shape, \n",
        "              n_actions=env.action_space.shape[0], \n",
        "              max_action=env.action_space.high[0], \n",
        "              min_action=env.action_space.low[0],\n",
        "              critic_learning_rate=0.01, actor_learning_rate=0.01, tau=0.1)\n",
        "agent.train(env, n_games=1000, warmup=1000)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run warmup ----------\n",
            "Start training ----------\n",
            "Episode 0 - trained steps 1600 - score -22.5 - avg_score -22.5 \n",
            "Episode 1 - trained steps 1690 - score -93.9 - avg_score -58.2 \n",
            "Episode 2 - trained steps 1831 - score -93.1 - avg_score -69.8 \n",
            "Episode 3 - trained steps 1953 - score -123.5 - avg_score -83.2 \n",
            "Episode 4 - trained steps 2040 - score -93.7 - avg_score -85.3 \n",
            "Episode 5 - trained steps 2137 - score -94.4 - avg_score -86.8 \n",
            "Episode 6 - trained steps 2277 - score -93.3 - avg_score -87.8 \n",
            "Episode 7 - trained steps 2372 - score -93.7 - avg_score -88.5 \n",
            "Episode 8 - trained steps 2511 - score -93.2 - avg_score -89.0 \n",
            "Episode 9 - trained steps 2629 - score -93.3 - avg_score -89.5 \n",
            "Episode 10 - trained steps 2722 - score -94.0 - avg_score -96.6 \n",
            "Episode 11 - trained steps 4322 - score -20.5 - avg_score -89.3 \n",
            "Episode 12 - trained steps 4428 - score -119.9 - avg_score -92.0 \n",
            "Episode 13 - trained steps 4528 - score -93.3 - avg_score -88.9 \n",
            "Episode 14 - trained steps 4665 - score -92.9 - avg_score -88.9 \n",
            "Episode 15 - trained steps 4781 - score -118.6 - avg_score -91.3 \n",
            "Episode 16 - trained steps 4926 - score -95.5 - avg_score -91.5 \n",
            "Episode 17 - trained steps 5023 - score -93.5 - avg_score -91.5 \n",
            "Episode 18 - trained steps 5112 - score -94.7 - avg_score -91.6 \n",
            "Episode 19 - trained steps 5201 - score -93.8 - avg_score -91.7 \n",
            "Episode 20 - trained steps 5281 - score -94.6 - avg_score -91.8 \n",
            "Episode 21 - trained steps 5404 - score -93.3 - avg_score -99.0 \n",
            "Episode 22 - trained steps 5642 - score -94.4 - avg_score -96.5 \n",
            "Episode 23 - trained steps 7242 - score -25.6 - avg_score -89.7 \n",
            "Episode 24 - trained steps 7341 - score -93.6 - avg_score -89.8 \n",
            "Episode 25 - trained steps 7428 - score -93.7 - avg_score -87.3 \n",
            "Episode 26 - trained steps 7548 - score -93.2 - avg_score -87.1 \n",
            "Episode 27 - trained steps 7638 - score -117.8 - avg_score -89.5 \n",
            "Episode 28 - trained steps 7712 - score -114.8 - avg_score -91.5 \n",
            "Episode 29 - trained steps 7801 - score -92.9 - avg_score -91.4 \n",
            "Episode 30 - trained steps 7893 - score -101.6 - avg_score -92.1 \n",
            "Episode 31 - trained steps 7983 - score -119.1 - avg_score -94.7 \n",
            "Episode 32 - trained steps 8092 - score -120.7 - avg_score -97.3 \n",
            "Episode 33 - trained steps 8171 - score -118.6 - avg_score -106.6 \n",
            "Episode 34 - trained steps 8270 - score -93.0 - avg_score -106.5 \n",
            "Episode 35 - trained steps 8363 - score -93.5 - avg_score -106.5 \n",
            "Episode 36 - trained steps 8492 - score -92.6 - avg_score -106.5 \n",
            "Episode 37 - trained steps 8597 - score -93.3 - avg_score -104.0 \n",
            "Episode 38 - trained steps 8798 - score -93.4 - avg_score -101.9 \n",
            "Episode 39 - trained steps 8896 - score -101.9 - avg_score -102.8 \n",
            "Episode 40 - trained steps 8980 - score -93.5 - avg_score -102.0 \n",
            "Episode 41 - trained steps 9072 - score -93.6 - avg_score -99.4 \n",
            "Episode 42 - trained steps 9178 - score -93.0 - avg_score -96.6 \n",
            "Episode 43 - trained steps 9266 - score -93.5 - avg_score -94.1 \n",
            "Episode 44 - trained steps 9365 - score -94.6 - avg_score -94.3 \n",
            "Episode 45 - trained steps 9511 - score -121.6 - avg_score -97.1 \n",
            "Episode 46 - trained steps 9603 - score -92.7 - avg_score -97.1 \n",
            "Episode 47 - trained steps 9768 - score -93.2 - avg_score -97.1 \n",
            "Episode 48 - trained steps 9900 - score -93.1 - avg_score -97.1 \n",
            "Episode 49 - trained steps 10022 - score -93.1 - avg_score -96.2 \n",
            "Episode 50 - trained steps 10128 - score -93.3 - avg_score -96.2 \n",
            "Episode 51 - trained steps 10224 - score -93.2 - avg_score -96.1 \n",
            "Episode 52 - trained steps 10315 - score -93.6 - avg_score -96.2 \n",
            "Episode 53 - trained steps 10434 - score -119.4 - avg_score -98.8 \n",
            "Episode 54 - trained steps 10517 - score -94.1 - avg_score -98.7 \n",
            "Episode 55 - trained steps 10613 - score -121.4 - avg_score -98.7 \n",
            "Episode 56 - trained steps 10713 - score -93.3 - avg_score -98.8 \n",
            "Episode 57 - trained steps 10809 - score -95.4 - avg_score -99.0 \n",
            "Episode 58 - trained steps 10943 - score -94.0 - avg_score -99.1 \n",
            "Episode 59 - trained steps 11048 - score -93.1 - avg_score -99.1 \n",
            "Episode 60 - trained steps 11161 - score -92.6 - avg_score -99.0 \n",
            "Episode 61 - trained steps 11284 - score -119.7 - avg_score -101.6 \n",
            "Episode 62 - trained steps 11383 - score -93.1 - avg_score -101.6 \n",
            "Episode 63 - trained steps 11491 - score -93.5 - avg_score -99.0 \n",
            "Episode 64 - trained steps 11604 - score -93.2 - avg_score -98.9 \n",
            "Episode 65 - trained steps 11795 - score -119.7 - avg_score -98.7 \n",
            "Episode 66 - trained steps 11923 - score -93.4 - avg_score -98.8 \n",
            "Episode 67 - trained steps 12011 - score -94.0 - avg_score -98.6 \n",
            "Episode 68 - trained steps 12104 - score -93.6 - avg_score -98.6 \n",
            "Episode 69 - trained steps 12183 - score -94.4 - avg_score -98.7 \n",
            "Episode 70 - trained steps 12327 - score -92.8 - avg_score -98.7 \n",
            "Episode 71 - trained steps 12452 - score -93.0 - avg_score -96.1 \n",
            "Episode 72 - trained steps 14052 - score -22.7 - avg_score -89.0 \n",
            "Episode 73 - trained steps 14172 - score -92.7 - avg_score -88.9 \n",
            "Episode 74 - trained steps 14275 - score -120.4 - avg_score -91.7 \n",
            "Episode 75 - trained steps 14371 - score -93.4 - avg_score -89.0 \n",
            "Episode 76 - trained steps 14481 - score -93.6 - avg_score -89.1 \n",
            "Episode 77 - trained steps 14608 - score -93.2 - avg_score -89.0 \n",
            "Episode 78 - trained steps 14738 - score -121.0 - avg_score -91.7 \n",
            "Episode 79 - trained steps 14851 - score -93.5 - avg_score -91.6 \n",
            "Episode 80 - trained steps 14940 - score -93.7 - avg_score -91.7 \n",
            "Episode 81 - trained steps 15052 - score -119.7 - avg_score -94.4 \n",
            "Episode 82 - trained steps 15123 - score -118.9 - avg_score -104.0 \n",
            "Episode 83 - trained steps 16723 - score -23.0 - avg_score -97.0 \n",
            "Episode 84 - trained steps 16858 - score -120.6 - avg_score -97.0 \n",
            "Episode 85 - trained steps 16954 - score -93.1 - avg_score -97.0 \n",
            "Episode 86 - trained steps 17037 - score -102.3 - avg_score -97.9 \n",
            "Episode 87 - trained steps 17129 - score -93.9 - avg_score -98.0 \n",
            "Episode 88 - trained steps 17242 - score -93.0 - avg_score -95.2 \n",
            "Episode 89 - trained steps 17334 - score -121.7 - avg_score -98.0 \n",
            "Episode 90 - trained steps 17414 - score -95.5 - avg_score -98.2 \n",
            "Episode 91 - trained steps 17517 - score -93.2 - avg_score -95.5 \n",
            "Episode 92 - trained steps 17630 - score -120.7 - avg_score -95.7 \n",
            "Episode 93 - trained steps 17746 - score -121.2 - avg_score -105.5 \n",
            "Episode 94 - trained steps 17847 - score -92.7 - avg_score -102.7 \n",
            "Episode 95 - trained steps 17913 - score -116.2 - avg_score -105.0 \n",
            "Episode 96 - trained steps 18007 - score -115.6 - avg_score -106.4 \n",
            "Episode 97 - trained steps 18129 - score -92.6 - avg_score -106.2 \n",
            "Episode 98 - trained steps 18233 - score -94.7 - avg_score -106.4 \n",
            "Episode 99 - trained steps 18331 - score -119.3 - avg_score -106.2 \n",
            "Episode 100 - trained steps 19931 - score -26.3 - avg_score -99.2 \n",
            "Episode 101 - trained steps 20035 - score -93.5 - avg_score -99.3 \n",
            "Episode 102 - trained steps 20197 - score -92.9 - avg_score -96.5 \n",
            "Episode 103 - trained steps 20290 - score -93.9 - avg_score -93.8 \n",
            "Episode 104 - trained steps 20426 - score -92.6 - avg_score -93.8 \n",
            "Episode 105 - trained steps 20532 - score -119.8 - avg_score -94.1 \n",
            "Episode 106 - trained steps 20594 - score -118.3 - avg_score -94.4 \n",
            "Episode 107 - trained steps 20682 - score -117.5 - avg_score -96.9 \n",
            "Episode 108 - trained steps 20774 - score -93.7 - avg_score -96.8 \n",
            "Episode 109 - trained steps 20895 - score -92.9 - avg_score -94.1 \n",
            "Episode 110 - trained steps 21014 - score -93.2 - avg_score -100.8 \n",
            "Episode 111 - trained steps 21120 - score -120.3 - avg_score -103.5 \n",
            "Episode 112 - trained steps 21273 - score -92.8 - avg_score -103.5 \n",
            "Episode 113 - trained steps 21457 - score -96.6 - avg_score -103.8 \n",
            "Episode 114 - trained steps 21548 - score -94.1 - avg_score -103.9 \n",
            "Episode 115 - trained steps 21702 - score -93.1 - avg_score -101.2 \n",
            "Episode 116 - trained steps 21815 - score -93.2 - avg_score -98.7 \n",
            "Episode 117 - trained steps 21922 - score -95.4 - avg_score -96.5 \n",
            "Episode 118 - trained steps 22030 - score -93.1 - avg_score -96.5 \n",
            "Episode 119 - trained steps 22127 - score -93.7 - avg_score -96.6 \n",
            "Episode 120 - trained steps 22574 - score -125.7 - avg_score -99.8 \n",
            "Episode 121 - trained steps 22651 - score -95.0 - avg_score -97.3 \n",
            "Episode 122 - trained steps 22766 - score -93.1 - avg_score -97.3 \n",
            "Episode 123 - trained steps 22891 - score -92.4 - avg_score -96.9 \n",
            "Episode 124 - trained steps 23007 - score -92.8 - avg_score -96.7 \n",
            "Episode 125 - trained steps 23123 - score -92.8 - avg_score -96.7 \n",
            "Episode 126 - trained steps 24723 - score -23.5 - avg_score -89.8 \n",
            "Episode 127 - trained steps 24883 - score -95.8 - avg_score -89.8 \n",
            "Episode 128 - trained steps 24972 - score -117.6 - avg_score -92.2 \n",
            "Episode 129 - trained steps 25142 - score -95.5 - avg_score -92.4 \n",
            "Episode 130 - trained steps 25261 - score -93.4 - avg_score -89.2 \n",
            "Episode 131 - trained steps 25351 - score -93.8 - avg_score -89.1 \n",
            "Episode 132 - trained steps 25454 - score -93.6 - avg_score -89.1 \n",
            "Episode 133 - trained steps 25589 - score -92.8 - avg_score -89.2 \n",
            "Episode 134 - trained steps 25718 - score -92.6 - avg_score -89.2 \n",
            "Episode 135 - trained steps 25784 - score -96.6 - avg_score -89.5 \n",
            "Episode 136 - trained steps 27384 - score -23.3 - avg_score -89.5 \n",
            "Episode 137 - trained steps 27477 - score -119.7 - avg_score -91.9 \n",
            "Episode 138 - trained steps 27600 - score -124.8 - avg_score -92.6 \n",
            "Episode 139 - trained steps 27761 - score -93.2 - avg_score -92.4 \n",
            "Episode 140 - trained steps 27851 - score -119.9 - avg_score -95.0 \n",
            "Episode 141 - trained steps 27971 - score -92.2 - avg_score -94.9 \n",
            "Episode 142 - trained steps 28097 - score -92.7 - avg_score -94.8 \n",
            "Episode 143 - trained steps 28258 - score -118.3 - avg_score -97.4 \n",
            "Episode 144 - trained steps 28356 - score -121.1 - avg_score -100.2 \n",
            "Episode 145 - trained steps 28484 - score -92.3 - avg_score -99.8 \n",
            "Episode 146 - trained steps 28573 - score -93.5 - avg_score -106.8 \n",
            "Episode 147 - trained steps 28667 - score -93.4 - avg_score -104.2 \n",
            "Episode 148 - trained steps 28794 - score -94.7 - avg_score -101.1 \n",
            "Episode 149 - trained steps 28880 - score -94.1 - avg_score -101.2 \n",
            "Episode 150 - trained steps 28964 - score -94.0 - avg_score -98.6 \n",
            "Episode 151 - trained steps 29069 - score -119.6 - avg_score -101.4 \n",
            "Episode 152 - trained steps 29161 - score -118.4 - avg_score -103.9 \n",
            "Episode 153 - trained steps 29229 - score -95.3 - avg_score -101.6 \n",
            "Episode 154 - trained steps 29320 - score -119.1 - avg_score -101.4 \n",
            "Episode 155 - trained steps 29420 - score -93.5 - avg_score -101.6 \n",
            "Episode 156 - trained steps 29537 - score -92.9 - avg_score -101.5 \n",
            "Episode 157 - trained steps 29644 - score -118.8 - avg_score -104.0 \n",
            "Episode 158 - trained steps 29704 - score -103.6 - avg_score -104.9 \n",
            "Episode 159 - trained steps 29791 - score -101.6 - avg_score -105.7 \n",
            "Episode 160 - trained steps 29924 - score -93.2 - avg_score -105.6 \n",
            "Episode 161 - trained steps 30032 - score -92.8 - avg_score -102.9 \n",
            "Episode 162 - trained steps 30136 - score -93.1 - avg_score -100.4 \n",
            "Episode 163 - trained steps 30216 - score -94.0 - avg_score -100.3 \n",
            "Episode 164 - trained steps 30287 - score -117.9 - avg_score -100.2 \n",
            "Episode 165 - trained steps 30389 - score -119.6 - avg_score -102.8 \n",
            "Episode 166 - trained steps 30488 - score -93.0 - avg_score -102.8 \n",
            "Episode 167 - trained steps 30565 - score -96.2 - avg_score -100.5 \n",
            "Episode 168 - trained steps 30672 - score -124.2 - avg_score -102.6 \n",
            "Episode 169 - trained steps 30748 - score -115.0 - avg_score -103.9 \n",
            "Episode 170 - trained steps 30853 - score -93.4 - avg_score -103.9 \n",
            "Episode 171 - trained steps 30936 - score -95.1 - avg_score -104.1 \n",
            "Episode 172 - trained steps 31069 - score -93.4 - avg_score -104.2 \n",
            "Episode 173 - trained steps 31166 - score -96.3 - avg_score -104.4 \n",
            "Episode 174 - trained steps 31304 - score -121.3 - avg_score -104.7 \n",
            "Episode 175 - trained steps 31408 - score -93.1 - avg_score -102.1 \n",
            "Episode 176 - trained steps 31503 - score -93.4 - avg_score -102.1 \n",
            "Episode 177 - trained steps 31637 - score -93.4 - avg_score -101.9 \n",
            "Episode 178 - trained steps 31746 - score -119.9 - avg_score -101.4 \n",
            "Episode 179 - trained steps 31853 - score -92.6 - avg_score -99.2 \n",
            "Episode 180 - trained steps 31991 - score -95.2 - avg_score -99.4 \n",
            "Episode 181 - trained steps 32116 - score -94.8 - avg_score -99.4 \n",
            "Episode 182 - trained steps 32200 - score -94.1 - avg_score -99.4 \n",
            "Episode 183 - trained steps 32281 - score -94.2 - avg_score -99.2 \n",
            "Episode 184 - trained steps 32369 - score -93.7 - avg_score -96.5 \n",
            "Episode 185 - trained steps 32448 - score -96.5 - avg_score -96.8 \n",
            "Episode 186 - trained steps 32554 - score -118.7 - avg_score -99.3 \n",
            "Episode 187 - trained steps 32642 - score -118.4 - avg_score -101.8 \n",
            "Episode 188 - trained steps 32764 - score -93.5 - avg_score -99.2 \n",
            "Episode 189 - trained steps 33060 - score -122.7 - avg_score -102.2 \n",
            "Episode 190 - trained steps 33168 - score -118.5 - avg_score -104.5 \n",
            "Episode 191 - trained steps 33262 - score -93.7 - avg_score -104.4 \n",
            "Episode 192 - trained steps 34862 - score -27.6 - avg_score -97.7 \n",
            "Episode 193 - trained steps 34990 - score -93.1 - avg_score -97.6 \n",
            "Episode 194 - trained steps 35081 - score -93.5 - avg_score -97.6 \n",
            "Episode 195 - trained steps 35218 - score -119.4 - avg_score -99.9 \n",
            "Episode 196 - trained steps 35347 - score -92.9 - avg_score -97.3 \n",
            "Episode 197 - trained steps 35410 - score -115.8 - avg_score -97.1 \n",
            "Episode 198 - trained steps 35532 - score -93.4 - avg_score -97.1 \n",
            "Episode 199 - trained steps 35639 - score -93.0 - avg_score -94.1 \n",
            "Episode 200 - trained steps 35747 - score -119.6 - avg_score -94.2 \n",
            "Episode 201 - trained steps 35892 - score -93.5 - avg_score -94.2 \n",
            "Episode 202 - trained steps 36003 - score -119.9 - avg_score -103.4 \n",
            "Episode 203 - trained steps 36091 - score -118.5 - avg_score -106.0 \n",
            "Episode 204 - trained steps 37691 - score -22.8 - avg_score -98.9 \n",
            "Episode 205 - trained steps 37771 - score -94.0 - avg_score -96.3 \n",
            "Episode 206 - trained steps 37883 - score -92.7 - avg_score -96.3 \n",
            "Episode 207 - trained steps 37970 - score -97.3 - avg_score -94.5 \n",
            "Episode 208 - trained steps 38100 - score -120.2 - avg_score -97.2 \n",
            "Episode 209 - trained steps 38177 - score -95.1 - avg_score -97.4 \n",
            "Episode 210 - trained steps 38291 - score -92.8 - avg_score -94.7 \n",
            "Episode 211 - trained steps 38412 - score -118.5 - avg_score -97.2 \n",
            "Episode 212 - trained steps 38515 - score -93.4 - avg_score -94.5 \n",
            "Episode 213 - trained steps 40115 - score -22.6 - avg_score -84.9 \n",
            "Episode 214 - trained steps 40197 - score -94.1 - avg_score -92.1 \n",
            "Episode 215 - trained steps 40314 - score -119.5 - avg_score -94.6 \n",
            "Episode 216 - trained steps 40399 - score -115.9 - avg_score -96.9 \n",
            "Episode 217 - trained steps 40541 - score -120.1 - avg_score -99.2 \n",
            "Episode 218 - trained steps 40670 - score -92.3 - avg_score -96.4 \n",
            "Episode 219 - trained steps 40765 - score -93.2 - avg_score -96.2 \n",
            "Episode 220 - trained steps 40905 - score -92.0 - avg_score -96.2 \n",
            "Episode 221 - trained steps 41021 - score -93.4 - avg_score -93.6 \n",
            "Episode 222 - trained steps 41117 - score -94.6 - avg_score -93.8 \n",
            "Episode 223 - trained steps 41229 - score -101.0 - avg_score -101.6 \n",
            "Episode 224 - trained steps 41342 - score -93.0 - avg_score -101.5 \n",
            "Episode 225 - trained steps 41402 - score -104.9 - avg_score -100.0 \n",
            "Episode 226 - trained steps 41508 - score -92.8 - avg_score -97.7 \n",
            "Episode 227 - trained steps 41602 - score -102.3 - avg_score -95.9 \n",
            "Episode 228 - trained steps 41743 - score -119.9 - avg_score -98.7 \n",
            "Episode 229 - trained steps 41844 - score -92.6 - avg_score -98.7 \n",
            "Episode 230 - trained steps 41944 - score -93.3 - avg_score -98.8 \n",
            "Episode 231 - trained steps 42049 - score -92.2 - avg_score -98.7 \n",
            "Episode 232 - trained steps 43649 - score -22.5 - avg_score -91.5 \n",
            "Episode 233 - trained steps 43746 - score -93.4 - avg_score -90.7 \n",
            "Episode 234 - trained steps 43835 - score -93.8 - avg_score -90.8 \n",
            "Episode 235 - trained steps 45435 - score -23.2 - avg_score -82.6 \n",
            "Episode 236 - trained steps 47035 - score -22.7 - avg_score -75.6 \n",
            "Episode 237 - trained steps 47176 - score -92.7 - avg_score -74.6 \n",
            "Episode 238 - trained steps 47277 - score -119.0 - avg_score -74.5 \n",
            "Episode 239 - trained steps 47380 - score -92.0 - avg_score -74.5 \n",
            "Episode 240 - trained steps 47497 - score -121.1 - avg_score -77.3 \n",
            "Episode 241 - trained steps 47625 - score -93.6 - avg_score -77.4 \n",
            "Episode 242 - trained steps 47711 - score -93.9 - avg_score -84.5 \n",
            "Episode 243 - trained steps 47824 - score -92.5 - avg_score -84.4 \n",
            "Episode 244 - trained steps 47923 - score -93.6 - avg_score -84.4 \n",
            "Episode 245 - trained steps 48033 - score -95.4 - avg_score -91.6 \n",
            "Episode 246 - trained steps 48143 - score -118.3 - avg_score -101.2 \n",
            "Episode 247 - trained steps 48256 - score -120.1 - avg_score -103.9 \n",
            "Episode 248 - trained steps 48373 - score -92.9 - avg_score -101.3 \n",
            "Episode 249 - trained steps 48490 - score -93.3 - avg_score -101.5 \n",
            "Episode 250 - trained steps 48590 - score -92.8 - avg_score -98.6 \n",
            "Episode 251 - trained steps 48703 - score -116.4 - avg_score -100.9 \n",
            "Episode 252 - trained steps 48955 - score -94.7 - avg_score -101.0 \n",
            "Episode 253 - trained steps 49062 - score -92.5 - avg_score -101.0 \n",
            "Episode 254 - trained steps 49146 - score -94.3 - avg_score -101.1 \n",
            "Episode 255 - trained steps 49252 - score -93.1 - avg_score -100.8 \n",
            "Episode 256 - trained steps 49362 - score -119.6 - avg_score -101.0 \n",
            "Episode 257 - trained steps 49453 - score -93.4 - avg_score -98.3 \n",
            "Episode 258 - trained steps 49730 - score -95.1 - avg_score -98.5 \n",
            "Episode 259 - trained steps 49849 - score -119.2 - avg_score -101.1 \n",
            "Episode 260 - trained steps 49936 - score -93.7 - avg_score -101.2 \n",
            "Episode 261 - trained steps 50080 - score -93.1 - avg_score -98.9 \n",
            "Episode 262 - trained steps 50165 - score -95.9 - avg_score -99.0 \n",
            "Episode 263 - trained steps 50245 - score -94.1 - avg_score -99.1 \n",
            "Episode 264 - trained steps 50403 - score -93.4 - avg_score -99.1 \n",
            "Episode 265 - trained steps 50545 - score -93.5 - avg_score -99.1 \n",
            "Episode 266 - trained steps 50672 - score -92.6 - avg_score -96.4 \n",
            "Episode 267 - trained steps 50781 - score -93.0 - avg_score -96.4 \n",
            "Episode 268 - trained steps 50870 - score -93.6 - avg_score -96.2 \n",
            "Episode 269 - trained steps 51009 - score -93.0 - avg_score -93.6 \n",
            "Episode 270 - trained steps 51105 - score -92.9 - avg_score -93.5 \n",
            "Episode 271 - trained steps 51201 - score -93.6 - avg_score -93.6 \n",
            "Episode 272 - trained steps 51308 - score -93.0 - avg_score -93.3 \n",
            "Episode 273 - trained steps 51398 - score -93.8 - avg_score -93.2 \n",
            "Episode 274 - trained steps 51519 - score -92.7 - avg_score -93.2 \n",
            "Episode 275 - trained steps 51637 - score -119.9 - avg_score -95.8 \n",
            "Episode 276 - trained steps 51744 - score -123.9 - avg_score -98.9 \n",
            "Episode 277 - trained steps 51893 - score -93.2 - avg_score -99.0 \n",
            "Episode 278 - trained steps 51995 - score -121.2 - avg_score -101.7 \n",
            "Episode 279 - trained steps 52116 - score -118.0 - avg_score -104.2 \n",
            "Episode 280 - trained steps 52201 - score -94.1 - avg_score -104.3 \n",
            "Episode 281 - trained steps 53801 - score -22.8 - avg_score -97.3 \n",
            "Episode 282 - trained steps 53913 - score -93.4 - avg_score -97.3 \n",
            "Episode 283 - trained steps 54187 - score -94.4 - avg_score -97.4 \n",
            "Episode 284 - trained steps 54274 - score -94.6 - avg_score -97.6 \n",
            "Episode 285 - trained steps 54417 - score -92.7 - avg_score -94.8 \n",
            "Episode 286 - trained steps 56017 - score -21.3 - avg_score -84.6 \n",
            "Episode 287 - trained steps 56092 - score -94.4 - avg_score -84.7 \n",
            "Episode 288 - trained steps 56199 - score -120.2 - avg_score -84.6 \n",
            "Episode 289 - trained steps 56393 - score -93.1 - avg_score -82.1 \n",
            "Episode 290 - trained steps 56509 - score -93.4 - avg_score -82.0 \n",
            "Episode 291 - trained steps 56602 - score -120.4 - avg_score -91.8 \n",
            "Episode 292 - trained steps 56710 - score -93.1 - avg_score -91.8 \n",
            "Episode 293 - trained steps 56787 - score -117.3 - avg_score -94.0 \n",
            "Episode 294 - trained steps 56879 - score -93.7 - avg_score -93.9 \n",
            "Episode 295 - trained steps 56974 - score -95.3 - avg_score -94.2 \n",
            "Episode 296 - trained steps 57083 - score -93.8 - avg_score -101.5 \n",
            "Episode 297 - trained steps 57185 - score -92.9 - avg_score -101.3 \n",
            "Episode 298 - trained steps 58785 - score -23.3 - avg_score -91.6 \n",
            "Episode 299 - trained steps 58910 - score -92.7 - avg_score -91.6 \n",
            "Episode 300 - trained steps 58973 - score -96.2 - avg_score -91.9 \n",
            "Episode 301 - trained steps 59066 - score -94.0 - avg_score -89.2 \n",
            "Episode 302 - trained steps 59159 - score -93.5 - avg_score -89.3 \n",
            "Episode 303 - trained steps 59264 - score -116.3 - avg_score -89.2 \n",
            "Episode 304 - trained steps 59352 - score -99.0 - avg_score -89.7 \n",
            "Episode 305 - trained steps 60952 - score -27.1 - avg_score -82.9 \n",
            "Episode 306 - trained steps 61033 - score -118.8 - avg_score -85.4 \n",
            "Episode 307 - trained steps 61126 - score -93.5 - avg_score -85.5 \n",
            "Episode 308 - trained steps 61195 - score -116.2 - avg_score -94.7 \n",
            "Episode 309 - trained steps 61291 - score -118.3 - avg_score -97.3 \n",
            "Episode 310 - trained steps 61407 - score -92.9 - avg_score -97.0 \n",
            "Episode 311 - trained steps 61503 - score -93.8 - avg_score -96.9 \n",
            "Episode 312 - trained steps 61677 - score -93.3 - avg_score -96.9 \n",
            "Episode 313 - trained steps 61766 - score -94.6 - avg_score -94.7 \n",
            "Episode 314 - trained steps 63366 - score -23.2 - avg_score -87.2 \n",
            "Episode 315 - trained steps 63502 - score -98.1 - avg_score -94.3 \n",
            "Episode 316 - trained steps 63617 - score -122.6 - avg_score -94.6 \n",
            "Episode 317 - trained steps 63730 - score -92.7 - avg_score -94.6 \n",
            "Episode 318 - trained steps 63845 - score -94.9 - avg_score -92.4 \n",
            "Episode 319 - trained steps 63951 - score -92.9 - avg_score -89.9 \n",
            "Episode 320 - trained steps 64054 - score -93.4 - avg_score -89.9 \n",
            "Episode 321 - trained steps 64147 - score -93.9 - avg_score -89.9 \n",
            "Episode 322 - trained steps 64258 - score -94.5 - avg_score -90.1 \n",
            "Episode 323 - trained steps 64377 - score -93.4 - avg_score -90.0 \n",
            "Episode 324 - trained steps 64487 - score -93.1 - avg_score -96.9 \n",
            "Episode 325 - trained steps 66087 - score -20.6 - avg_score -89.2 \n",
            "Episode 326 - trained steps 66216 - score -93.2 - avg_score -86.3 \n",
            "Episode 327 - trained steps 66293 - score -118.6 - avg_score -88.8 \n",
            "Episode 328 - trained steps 66423 - score -92.6 - avg_score -88.6 \n",
            "Episode 329 - trained steps 66528 - score -92.5 - avg_score -88.6 \n",
            "Episode 330 - trained steps 66634 - score -93.4 - avg_score -88.6 \n",
            "Episode 331 - trained steps 66751 - score -93.1 - avg_score -88.5 \n",
            "Episode 332 - trained steps 66849 - score -96.3 - avg_score -88.7 \n",
            "Episode 333 - trained steps 66970 - score -120.4 - avg_score -91.4 \n",
            "Episode 334 - trained steps 67074 - score -120.5 - avg_score -94.1 \n",
            "Episode 335 - trained steps 67182 - score -93.7 - avg_score -101.4 \n",
            "Episode 336 - trained steps 67293 - score -93.9 - avg_score -101.5 \n",
            "Episode 337 - trained steps 67425 - score -93.5 - avg_score -99.0 \n",
            "Episode 338 - trained steps 67510 - score -118.3 - avg_score -101.6 \n",
            "Episode 339 - trained steps 67628 - score -118.6 - avg_score -104.2 \n",
            "Episode 340 - trained steps 67748 - score -93.3 - avg_score -104.2 \n",
            "Episode 341 - trained steps 67826 - score -94.4 - avg_score -104.3 \n",
            "Episode 342 - trained steps 69426 - score -23.0 - avg_score -97.0 \n",
            "Episode 343 - trained steps 69542 - score -95.2 - avg_score -94.4 \n",
            "Episode 344 - trained steps 71142 - score -25.9 - avg_score -85.0 \n",
            "Episode 345 - trained steps 71243 - score -93.3 - avg_score -84.9 \n",
            "Episode 346 - trained steps 71318 - score -95.9 - avg_score -85.1 \n",
            "Episode 347 - trained steps 71411 - score -93.6 - avg_score -85.1 \n",
            "Episode 348 - trained steps 71524 - score -93.0 - avg_score -82.6 \n",
            "Episode 349 - trained steps 73124 - score -25.2 - avg_score -73.3 \n",
            "Episode 350 - trained steps 73260 - score -92.9 - avg_score -73.2 \n",
            "Episode 351 - trained steps 73345 - score -94.2 - avg_score -73.2 \n",
            "Episode 352 - trained steps 73427 - score -93.9 - avg_score -80.3 \n",
            "Episode 353 - trained steps 73489 - score -96.3 - avg_score -80.4 \n",
            "Episode 354 - trained steps 73590 - score -118.3 - avg_score -89.7 \n",
            "Episode 355 - trained steps 73675 - score -119.2 - avg_score -92.2 \n",
            "Episode 356 - trained steps 73771 - score -93.3 - avg_score -92.0 \n",
            "Episode 357 - trained steps 73870 - score -93.2 - avg_score -91.9 \n",
            "Episode 358 - trained steps 73967 - score -93.6 - avg_score -92.0 \n",
            "Episode 359 - trained steps 74067 - score -95.6 - avg_score -99.0 \n",
            "Episode 360 - trained steps 74169 - score -120.7 - avg_score -101.8 \n",
            "Episode 361 - trained steps 74252 - score -94.8 - avg_score -101.9 \n",
            "Episode 362 - trained steps 74370 - score -120.1 - avg_score -104.5 \n",
            "Episode 363 - trained steps 74471 - score -93.2 - avg_score -104.2 \n",
            "Episode 364 - trained steps 74589 - score -93.1 - avg_score -101.7 \n",
            "Episode 365 - trained steps 74684 - score -119.1 - avg_score -101.7 \n",
            "Episode 366 - trained steps 74839 - score -92.8 - avg_score -101.6 \n",
            "Episode 367 - trained steps 74941 - score -118.4 - avg_score -104.1 \n",
            "Episode 368 - trained steps 75050 - score -97.7 - avg_score -104.6 \n",
            "Episode 369 - trained steps 76650 - score -20.5 - avg_score -97.0 \n",
            "Episode 370 - trained steps 76754 - score -93.0 - avg_score -94.3 \n",
            "Episode 371 - trained steps 76894 - score -93.3 - avg_score -94.1 \n",
            "Episode 372 - trained steps 76989 - score -94.0 - avg_score -91.5 \n",
            "Episode 373 - trained steps 77100 - score -92.9 - avg_score -91.5 \n",
            "Episode 374 - trained steps 77212 - score -92.7 - avg_score -91.4 \n",
            "Episode 375 - trained steps 77302 - score -93.7 - avg_score -88.9 \n",
            "Episode 376 - trained steps 77410 - score -118.8 - avg_score -91.5 \n",
            "Episode 377 - trained steps 77521 - score -93.2 - avg_score -89.0 \n",
            "Episode 378 - trained steps 77614 - score -93.4 - avg_score -88.6 \n",
            "Episode 379 - trained steps 77697 - score -94.1 - avg_score -95.9 \n",
            "Episode 380 - trained steps 79297 - score -21.8 - avg_score -88.8 \n",
            "Episode 381 - trained steps 79410 - score -121.1 - avg_score -91.6 \n",
            "Episode 382 - trained steps 79500 - score -93.8 - avg_score -91.6 \n",
            "Episode 383 - trained steps 79590 - score -94.3 - avg_score -91.7 \n",
            "Episode 384 - trained steps 79668 - score -117.3 - avg_score -94.2 \n",
            "Episode 385 - trained steps 79779 - score -92.9 - avg_score -94.1 \n",
            "Episode 386 - trained steps 79907 - score -92.9 - avg_score -91.5 \n",
            "Episode 387 - trained steps 79999 - score -119.5 - avg_score -94.1 \n",
            "Episode 388 - trained steps 81599 - score -22.9 - avg_score -87.1 \n",
            "Episode 389 - trained steps 83199 - score -22.6 - avg_score -79.9 \n",
            "Episode 390 - trained steps 83320 - score -119.8 - avg_score -89.7 \n",
            "Episode 391 - trained steps 83411 - score -93.9 - avg_score -87.0 \n",
            "Episode 392 - trained steps 83522 - score -92.8 - avg_score -86.9 \n",
            "Episode 393 - trained steps 83628 - score -94.3 - avg_score -86.9 \n",
            "Episode 394 - trained steps 83929 - score -121.9 - avg_score -87.3 \n",
            "Episode 395 - trained steps 84040 - score -93.1 - avg_score -87.4 \n",
            "Episode 396 - trained steps 85640 - score -22.5 - avg_score -80.3 \n",
            "Episode 397 - trained steps 85740 - score -93.4 - avg_score -77.7 \n",
            "Episode 398 - trained steps 85878 - score -120.6 - avg_score -87.5 \n",
            "Episode 399 - trained steps 86020 - score -93.0 - avg_score -94.5 \n",
            "Episode 400 - trained steps 86111 - score -93.7 - avg_score -91.9 \n",
            "Episode 401 - trained steps 86243 - score -92.5 - avg_score -91.8 \n",
            "Episode 402 - trained steps 86371 - score -92.7 - avg_score -91.8 \n",
            "Episode 403 - trained steps 86465 - score -93.5 - avg_score -91.7 \n",
            "Episode 404 - trained steps 86546 - score -93.9 - avg_score -88.9 \n",
            "Episode 405 - trained steps 86686 - score -92.7 - avg_score -88.8 \n",
            "Episode 406 - trained steps 88286 - score -23.3 - avg_score -88.9 \n",
            "Episode 407 - trained steps 89886 - score -23.8 - avg_score -82.0 \n",
            "Episode 408 - trained steps 89984 - score -122.0 - avg_score -82.1 \n",
            "Episode 409 - trained steps 90083 - score -92.7 - avg_score -82.1 \n",
            "Episode 410 - trained steps 91683 - score -23.3 - avg_score -75.0 \n",
            "Episode 411 - trained steps 91768 - score -93.8 - avg_score -75.2 \n",
            "Episode 412 - trained steps 91838 - score -96.4 - avg_score -75.5 \n",
            "Episode 413 - trained steps 93438 - score -22.7 - avg_score -68.5 \n",
            "Episode 414 - trained steps 93523 - score -119.0 - avg_score -71.0 \n",
            "Episode 415 - trained steps 93633 - score -121.3 - avg_score -73.8 \n",
            "Episode 416 - trained steps 93729 - score -96.8 - avg_score -81.2 \n",
            "Episode 417 - trained steps 93814 - score -101.7 - avg_score -89.0 \n",
            "Episode 418 - trained steps 93918 - score -93.3 - avg_score -86.1 \n",
            "Episode 419 - trained steps 94019 - score -94.0 - avg_score -86.2 \n",
            "Episode 420 - trained steps 94110 - score -93.9 - avg_score -93.3 \n",
            "Episode 421 - trained steps 94244 - score -92.8 - avg_score -93.2 \n",
            "Episode 422 - trained steps 95844 - score -23.1 - avg_score -85.9 \n",
            "Episode 423 - trained steps 95943 - score -93.1 - avg_score -92.9 \n",
            "Episode 424 - trained steps 96050 - score -95.0 - avg_score -90.5 \n",
            "Episode 425 - trained steps 96201 - score -92.4 - avg_score -87.6 \n",
            "Episode 426 - trained steps 96289 - score -93.9 - avg_score -87.3 \n",
            "Episode 427 - trained steps 96409 - score -118.3 - avg_score -89.0 \n",
            "Episode 428 - trained steps 96523 - score -92.9 - avg_score -88.9 \n",
            "Episode 429 - trained steps 96671 - score -119.0 - avg_score -91.4 \n",
            "Episode 430 - trained steps 96873 - score -94.5 - avg_score -91.5 \n",
            "Episode 431 - trained steps 97019 - score -92.7 - avg_score -91.5 \n",
            "Episode 432 - trained steps 97120 - score -93.4 - avg_score -98.5 \n",
            "Episode 433 - trained steps 97209 - score -94.1 - avg_score -98.6 \n",
            "Episode 434 - trained steps 97322 - score -92.6 - avg_score -98.4 \n",
            "Episode 435 - trained steps 97429 - score -92.8 - avg_score -98.4 \n",
            "Episode 436 - trained steps 97547 - score -92.5 - avg_score -98.3 \n",
            "Episode 437 - trained steps 97637 - score -93.6 - avg_score -95.8 \n",
            "Episode 438 - trained steps 99237 - score -25.3 - avg_score -89.1 \n",
            "Episode 439 - trained steps 99401 - score -119.1 - avg_score -89.1 \n",
            "Episode 440 - trained steps 99499 - score -118.0 - avg_score -91.4 \n",
            "Episode 441 - trained steps 99601 - score -119.0 - avg_score -94.0 \n",
            "Episode 442 - trained steps 99697 - score -94.5 - avg_score -94.1 \n",
            "Episode 443 - trained steps 99786 - score -93.9 - avg_score -94.1 \n",
            "Episode 444 - trained steps 99895 - score -119.3 - avg_score -96.8 \n",
            "Episode 445 - trained steps 99992 - score -93.9 - avg_score -96.9 \n",
            "Episode 446 - trained steps 100070 - score -117.8 - avg_score -99.4 \n",
            "Episode 447 - trained steps 100169 - score -93.0 - avg_score -99.4 \n",
            "Episode 448 - trained steps 100291 - score -92.8 - avg_score -106.1 \n",
            "Episode 449 - trained steps 100408 - score -92.8 - avg_score -103.5 \n",
            "Episode 450 - trained steps 102008 - score -23.0 - avg_score -94.0 \n",
            "Episode 451 - trained steps 102167 - score -93.0 - avg_score -91.4 \n",
            "Episode 452 - trained steps 102270 - score -93.2 - avg_score -91.3 \n",
            "Episode 453 - trained steps 102392 - score -92.9 - avg_score -91.2 \n",
            "Episode 454 - trained steps 102503 - score -93.3 - avg_score -88.6 \n",
            "Episode 455 - trained steps 102613 - score -92.9 - avg_score -88.5 \n",
            "Episode 456 - trained steps 102762 - score -93.1 - avg_score -86.0 \n",
            "Episode 457 - trained steps 102860 - score -93.2 - avg_score -86.0 \n",
            "Episode 458 - trained steps 102989 - score -93.1 - avg_score -86.1 \n",
            "Episode 459 - trained steps 103120 - score -94.4 - avg_score -86.2 \n",
            "Episode 460 - trained steps 103247 - score -119.7 - avg_score -95.9 \n",
            "Episode 461 - trained steps 103308 - score -101.4 - avg_score -96.7 \n",
            "Episode 462 - trained steps 104908 - score -21.8 - avg_score -89.6 \n",
            "Episode 463 - trained steps 105033 - score -94.8 - avg_score -89.8 \n",
            "Episode 464 - trained steps 105163 - score -93.1 - avg_score -89.7 \n",
            "Episode 465 - trained steps 105264 - score -93.5 - avg_score -89.8 \n",
            "Episode 466 - trained steps 105356 - score -93.9 - avg_score -89.9 \n",
            "Episode 467 - trained steps 105430 - score -101.2 - avg_score -90.7 \n",
            "Episode 468 - trained steps 105542 - score -93.7 - avg_score -90.7 \n",
            "Episode 469 - trained steps 105663 - score -93.6 - avg_score -90.7 \n",
            "Episode 470 - trained steps 105780 - score -92.8 - avg_score -88.0 \n",
            "Episode 471 - trained steps 105887 - score -118.0 - avg_score -89.6 \n",
            "Episode 472 - trained steps 105969 - score -95.6 - avg_score -97.0 \n",
            "Episode 473 - trained steps 106080 - score -92.8 - avg_score -96.8 \n",
            "Episode 474 - trained steps 106176 - score -118.9 - avg_score -99.4 \n",
            "Episode 475 - trained steps 106358 - score -93.8 - avg_score -99.4 \n",
            "Episode 476 - trained steps 106472 - score -93.2 - avg_score -99.3 \n",
            "Episode 477 - trained steps 106565 - score -101.1 - avg_score -99.3 \n",
            "Episode 478 - trained steps 106674 - score -94.9 - avg_score -99.5 \n",
            "Episode 479 - trained steps 106756 - score -119.2 - avg_score -102.0 \n",
            "Episode 480 - trained steps 106881 - score -93.3 - avg_score -102.1 \n",
            "Episode 481 - trained steps 107024 - score -92.7 - avg_score -99.5 \n",
            "Episode 482 - trained steps 107169 - score -92.9 - avg_score -99.3 \n",
            "Episode 483 - trained steps 107234 - score -115.6 - avg_score -101.6 \n",
            "Episode 484 - trained steps 107381 - score -93.2 - avg_score -99.0 \n",
            "Episode 485 - trained steps 107514 - score -93.0 - avg_score -98.9 \n",
            "Episode 486 - trained steps 109114 - score -23.8 - avg_score -92.0 \n",
            "Episode 487 - trained steps 109216 - score -94.1 - avg_score -91.3 \n",
            "Episode 488 - trained steps 109322 - score -93.3 - avg_score -91.1 \n",
            "Episode 489 - trained steps 109483 - score -94.7 - avg_score -88.7 \n",
            "Episode 490 - trained steps 109577 - score -93.6 - avg_score -88.7 \n",
            "Episode 491 - trained steps 109723 - score -93.3 - avg_score -88.7 \n",
            "Episode 492 - trained steps 111323 - score -27.6 - avg_score -82.2 \n",
            "Episode 493 - trained steps 111424 - score -93.4 - avg_score -80.0 \n",
            "Episode 494 - trained steps 111525 - score -93.2 - avg_score -80.0 \n",
            "Episode 495 - trained steps 111612 - score -94.6 - avg_score -80.1 \n",
            "Episode 496 - trained steps 113212 - score -22.8 - avg_score -80.0 \n",
            "Episode 497 - trained steps 113307 - score -119.4 - avg_score -82.6 \n",
            "Episode 498 - trained steps 113403 - score -119.6 - avg_score -85.2 \n",
            "Episode 499 - trained steps 113480 - score -113.7 - avg_score -87.1 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-783dd6b7e4e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mmin_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               critic_learning_rate=0.01, actor_learning_rate=0.01, tau=0.1)\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_games\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-679dbfeb10fd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, env, n_games, warmup)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-679dbfeb10fd>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mcritic2_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mcritic1_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic1_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mcritic2_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic2_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic1_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic2_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MaximumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1585\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_MaximumGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m   \u001b[0;34m\"\"\"Returns grad*(x > y, x <= y) with type of grad.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1587\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_MaximumMinimumGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater_equal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MaximumMinimumGrad\u001b[0;34m(op, grad, selector_op)\u001b[0m\n\u001b[1;32m   1557\u001b[0m       \u001b[0;31m# When we want to get gradients for the first input only, and the second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m       \u001b[0;31m# input tensor is a scalar, we can do a much simpler calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1559\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_MaximumMinimumGradInputOnly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselector_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1560\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m     \u001b[0;31m# No gradient skipping, so do the full gradient computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MaximumMinimumGradInputOnly\u001b[0;34m(op, grad, selector_op)\u001b[0m\n\u001b[1;32m   1541\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m   \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m   \u001b[0mxmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1544\u001b[0m   \u001b[0mxgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m   \u001b[0mygrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Return None for ygrad since the config allows that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mgreater_equal\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   4031\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4032\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 4033\u001b[0;31m         _ctx, \"GreaterEqual\", name, x, y)\n\u001b[0m\u001b[1;32m   4034\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4035\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmphIwVZ4nQi"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFNi_q964nQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f38c6e3-e314-4379-902c-ab04d5c47293"
      },
      "source": [
        "episodes = 3\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0 \n",
        "    steps = 0\n",
        "    while not done:\n",
        "        # env.render()        \n",
        "        action = agent.choose_action(state)\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score += reward\n",
        "        steps += 1\n",
        "    print('Episode:{} Steps:{} Score:{}'.format(episode, steps, score))\n",
        "env.close()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode:1 Steps:68 Score:-111.47085458498387\n",
            "Episode:2 Steps:67 Score:-111.39512511405162\n",
            "Episode:3 Steps:68 Score:-111.67204202689169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDyHBWk0svdH"
      },
      "source": [
        "state = env.reset()\n",
        "action = agent.choose_action(state)\n",
        "action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SayFKSlAslxA"
      },
      "source": [
        "# TD3 pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou2KweMRslxC"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYZiwUdUslxC"
      },
      "source": [
        "## Experience Replay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m94HBc8jslxD"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvRGYBbuslxE"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYia-ZYRslxE"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8HstlOrslxF"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UB6REOAslxF"
      },
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}